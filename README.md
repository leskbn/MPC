# MPC
수업 프로젝트였던 것 (매우 미흡,,)

흐름
Gymnasium 환경에서 랜덤 액션으로 인한 결과 데이터(현재 상태 + 낸 액션 + 해당 액션 적용 후 상태) 저장 
-> 해당 데이터로 현재 상태 + 액션에서 어떤 상태(각도만)가 될지 예측하는 딥러닝 모델 학습 
-> 해당 모델로 시뮬레이션 상 제어 실험

 GPT 추천 업그레이드 방향
1.	전체 다음 상태 예측
•	출력 차원을 4로 늘려 [x’, ẋ’, θ’, θ̇’] 또는 최소한 [θ’, θ̇’]을 예측.
•	롤아웃에서 예측된 전체 상태로 다음 입력을 업데이트 → 일관된 멀티스텝 시뮬 가능.

2.	Δ-모델(차분 예측)
•	절대 다음값 대신 Δstate = next - current를 예측하면 학습이 더 잘 되는 경우 많음

3.	DAgger/데이터 증강 루프
•	현재 MPC로 실행하면서 새 전이를 계속 추가 수집 → 주기적으로 재학습(분포 불일치 완화).
	
4.	비용 함수 고도화
•	cost = wθ|θ| + wθdot|θ̇| + wX|x| + wXdot|ẋ| 식으로 가중치 튜닝.
•	또는 제곱합(2-노름)으로 매끈하게: cost = θ^2 + 0.1 θ̇^2 + 0.001 x^2 + 0.001 ẋ^2.
	
5.	학습 파이프라인 개선
•	미니배치, 셔플, early stopping, 러닝레이트 스케줄러, 시드 고정 등 기본기 정돈.
